{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for research project - Real-time Route Planning for Reducing Pedestrian
Pollution Exposure in Urban Areas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read map data\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "point_coor = pd.read_csv(\"map_point.csv\")\n",
    "\n",
    "# Data preprocessing of point data\n",
    "find_longitude = re.compile(r'[(](.*)[ ]', re.S)\n",
    "find_latitude = re.compile(r'[0-9][ ](.*)[)]', re.S)\n",
    "find_id = re.compile(r'[ ](.*)')\n",
    "\n",
    "point_id =[]\n",
    "point_longitude = []\n",
    "point_latitude = []\n",
    "for index, row in point_coor.iterrows():\n",
    "    point_longitude.append(re.findall(find_longitude, row[0])[0])\n",
    "    point_latitude.append(re.findall(find_latitude, row[0])[0])\n",
    "    point_id.append(re.findall(find_id, row[1])[0])\n",
    "    \n",
    "point_df = pd.DataFrame({\n",
    "            'point_id': point_id,\n",
    "            'longitude': point_longitude,\n",
    "            'latitude': point_latitude\n",
    "                                          })\n",
    "point_df.to_csv('point_data_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the map data and store into the dictionary\n",
    "point_data = pd.read_csv(\"point_data_clean.csv\")\n",
    "\n",
    "point_conn = pd.read_excel(\"point_connection.xlsx\")\n",
    "\n",
    "# Data propressing of point_connection\n",
    "point_connection = list(point_conn['connection'])\n",
    "point_conn_lst = []\n",
    "for i in point_connection:\n",
    "    point_conn_lst.append(i.split(' '))\n",
    "    \n",
    "point_conn['connection_lst'] = point_conn_lst\n",
    "\n",
    "# Merge two dataframe point data(Coordinate points) and point_conn(point connection information)\n",
    "point_total = pd.merge(point_data, point_conn, how='inner', on='point_id')\n",
    "\n",
    "# Store the data into dictionary in the format {id: {longitude, latitude, connection point}}\n",
    "point_dict = dict()\n",
    "for index, row in point_total.iterrows():\n",
    "    point_dict[str(row[0])] = dict()\n",
    "    point_dict[str(row[0])]['longitude'] = row[1]\n",
    "    point_dict[str(row[0])]['latitude'] = row[2]\n",
    "    point_dict[str(row[0])]['connection_lst'] = row[4]\n",
    "    \n",
    "connection_set = set()\n",
    "point_coor = dict()\n",
    "key_number = point_dict.keys()\n",
    "# print(key_number)\n",
    "for i in key_number:\n",
    "    point_coor[i] = str(point_dict[i]['latitude']) + \",\" + str(point_dict[i]['longitude'])\n",
    "    connection_lst = point_dict[i]['connection_lst']\n",
    "    for j in connection_lst:\n",
    "        if (i, j) not in connection_set and (j, i) not in connection_set:\n",
    "            connection_set.add((i, j))           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the format from a series of numbers to the LineString, which can directly shown in the google map\n",
    "# LineString is a one-dimensional object representing a sequence of points and the line segments connecting them\n",
    "from shapely import wkt\n",
    "from shapely.geometry import LineString\n",
    "def draw_router(line_lst):\n",
    "    string = \"LINESTRING (\"\n",
    "    point_lst = []\n",
    "    for i in range (len(line_lst)):\n",
    "        point_id = line_lst[i]\n",
    "        point_lst.append((point_dict[point_id]['longitude'], point_dict[point_id]['latitude']))\n",
    "        \n",
    "    return LineString(point_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "def get_distance(coords_1, coords_2):\n",
    "    return geopy.distance.geodesic(coords_1, coords_2).m\n",
    "\n",
    "def preprocess_airbeam(real_data):\n",
    "    real_latitude = real_data['Latitude']\n",
    "    real_longitude = real_data['Longitude']\n",
    "    real_PM_lst = real_data['AirBeam2-PM2.5']\n",
    "\n",
    "    real_data_dict = dict()\n",
    "    for i in range(len(real_latitude)):\n",
    "        for (start_point, end_point) in connection_set:\n",
    "            start_coor = (point_dict[start_point]['latitude'], point_dict[start_point]['longitude']) \n",
    "            end_coor = (point_dict[end_point]['latitude'], point_dict[end_point]['longitude'])\n",
    "            total_distance = get_distance(start_coor, end_coor)\n",
    "\n",
    "            real_coor = (real_latitude[i],real_longitude[i])\n",
    "            left = get_distance(start_coor, real_coor)\n",
    "            right = get_distance(real_coor, end_coor)\n",
    "    #         print(abs(total_distance - (left + right)))\n",
    "\n",
    "            if abs(total_distance - (left + right)) < 2:\n",
    "                if (start_point, end_point) not in real_data_dict:\n",
    "                    real_data_dict[(start_point, end_point)] = [real_PM_lst[i]]\n",
    "                else:\n",
    "                    real_data_dict[(start_point, end_point)].append(real_PM_lst[i])\n",
    "                break\n",
    "\n",
    "    PM_dict = dict()\n",
    "    for i in real_data_dict.keys():\n",
    "        pm_lst = real_data_dict[i]\n",
    "        pm_lst = [x for x in pm_lst if str(x) != 'nan']\n",
    "        real_PM = sum(pm_lst) / len(pm_lst)\n",
    "        PM_dict[i] = real_PM\n",
    "    return PM_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Real time Traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Require the traffic data from google map platform\n",
    "import requests\n",
    "import json\n",
    "def get_result_traffic(original, destination):\n",
    "    \n",
    "    # replace to the privacy key when using\n",
    "    my_key = actual_key\n",
    "    \n",
    "    url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins=\" + original +\"&destinations=\" + destination + '&departure_time=now' + \"&key=\" + my_key\n",
    "    payload = {}\n",
    "    headers = {}\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each street traffic data and store the traffic data into the dictionary\n",
    "def traffic_volume():\n",
    "    traffic_value_dict = dict()\n",
    "    for i in connection_set:\n",
    "        original = point_coor[i[0]]\n",
    "        destination = point_coor[i[1]]\n",
    "\n",
    "        result_traffic = get_result_traffic(original, destination)\n",
    "        result_traffic_json = json.loads(result_traffic)\n",
    "\n",
    "        traffic_value_dict[i] = result_traffic_json\n",
    "\n",
    "    # preprocess the traffic data and store into one hour volume\n",
    "    traffic_value_num = dict()\n",
    "    traffic = []\n",
    "    for i in connection_set:\n",
    "        require_result = traffic_value_dict[i]['rows'][0]['elements'][0]['duration_in_traffic']\n",
    "        traffic_time = int(require_result['text'][:-4])\n",
    "        traffic_value = require_result['value']\n",
    "        one_hour = traffic_value * (60 / traffic_time)\n",
    "        traffic_value_num[i] = one_hour\n",
    "        traffic.append(one_hour) \n",
    "        \n",
    "    return traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PM2.5 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_id_dict = {}\n",
    "site_df = pd.read_excel(\"site_id.xlsx\")\n",
    "\n",
    "for index, row in site_df.iterrows():\n",
    "    site_id_dict[row['Name']] = row['SiteID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EPA_PM(site_id):\n",
    "    url = \"https://gateway.api.epa.vic.gov.au/environmentMonitoring/v1/sites/\"+site_id+\"/parameters\"\n",
    "    # replace to the privacy key when using\n",
    "    headers = {\"X-API-Key\": actual_key, 'User-Agent': 'My User Agent 1.0'}\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    json_PM = json.loads(response.text)\n",
    "    coordinate = json_PM['geometry']['coordinates']\n",
    "    current_PM = json_PM['parameters'][0]['timeSeriesReadings'][0]['readings'][0]['averageValue']\n",
    "    return current_PM,coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pykrige.rk import RegressionKriging\n",
    "\n",
    "def regression_kriging(site_id_dict):\n",
    "    lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "    p_train = []\n",
    "    x_train = []\n",
    "    target_train = []\n",
    "    p_test = []\n",
    "    x_test = []\n",
    "    target_test = []\n",
    "\n",
    "    for i in site_id_dict.keys():\n",
    "#         print(i)\n",
    "        try:\n",
    "            data = get_EPA_PM(site_id_dict[i])\n",
    "#             print(data)\n",
    "            if data[0] <= 0:\n",
    "                continue\n",
    "\n",
    "            if i == \"Melbourne CBD\":\n",
    "                p_test.append(data[1])\n",
    "                x_test.append(data[1])\n",
    "                target_test.append(data[0])\n",
    "\n",
    "            else:\n",
    "                p_train.append(data[1])\n",
    "                x_train.append(data[1])\n",
    "                target_train.append(data[0])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "#     print(np.array(p_train), x_train, target_train)\n",
    "#     print(p_test, x_test, target_test)\n",
    "    m_rk = RegressionKriging(regression_model=lr_model, n_closest_points=len(x_train))\n",
    "    m_rk.fit(np.array(p_train), np.array(x_train), np.array(target_train))\n",
    "#     print(m_rk.predict(np.array(p_test), np.array(x_test)))\n",
    "    return float(m_rk.predict(np.array(p_test), np.array(x_test))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "R2 0.7525387811223261\n",
      "RMSE 2.014186910266206\n",
      "MAE 0.8179998131171565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "             early_stopping_rounds=None, enable_categorical=False, eta=0.1,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "             grow_policy='depthwise', importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.100000001, max_bin=256,\n",
       "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "             max_depth=8, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=1000, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('final_data.csv')\n",
    "feature = dataset[['traffic','temperture','relative_humidity','wind_direction','wind_speed','pressure','condition','EPA']]\n",
    "label = dataset['PM']\n",
    "import xgboost\n",
    "from xgboost import cv\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "xgboost = xgboost.XGBRegressor(n_estimators=1000, max_depth=8, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "xgb_score = cross_validate(xgboost, feature, label, cv=10,\n",
    "                        scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_error'),\n",
    "                         return_train_score=True)\n",
    "from numpy import absolute\n",
    "print(\"XGBoost\")\n",
    "print(\"R2\", xgb_score['test_r2'].mean())\n",
    "print(\"RMSE\", absolute(xgb_score['test_neg_root_mean_squared_error']).mean())\n",
    "print(\"MAE\",  absolute(xgb_score['test_neg_mean_absolute_error']).mean())\n",
    "\n",
    "xgboost.fit(feature,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to store the model\n",
    "# import pickle\n",
    "# pickle.dump(xgboost,open(\"new_xgboost.dat\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression\n",
      "R2 0.35100072839677745\n",
      "RMSE 3.521226995984552\n",
      "MAE 2.78139335123301\n"
     ]
    }
   ],
   "source": [
    "# baseline - linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(7)\n",
    "poly_feature = poly.fit_transform(feature)\n",
    "lr_reg = LinearRegression(positive=True)\n",
    "lr_score = cross_validate(lr_reg, poly_feature, label, cv=10,\n",
    "                        scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_error'),\n",
    "                         return_train_score=True)\n",
    "\n",
    "from numpy import absolute\n",
    "print(\"Linear regression\")\n",
    "print(\"R2\", lr_score['test_r2'].mean())\n",
    "print(\"RMSE\", absolute(lr_score['test_neg_root_mean_squared_error']).mean())\n",
    "print(\"MAE\",  absolute(lr_score['test_neg_mean_absolute_error']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Minimum distance dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "import geopy.distance\n",
    "\n",
    "# Get the distance between two points based on the latitude and longitude\n",
    "def get_distance(coords_1, coords_2):\n",
    "    return geopy.distance.geodesic(coords_1, coords_2).m\n",
    "\n",
    "# Generate minimum distance route based on dijkstra\n",
    "def dijkstra_distance(start, end, point_dict):\n",
    "    dist = dict()\n",
    "    for i in point_dict.keys():\n",
    "        dist[i] = float(\"inf\")\n",
    "    \n",
    "    pred = dict()\n",
    "    for i in point_dict.keys():\n",
    "        pred[i] = 0\n",
    "\n",
    "    dist[start] = 0\n",
    "    \n",
    "    Q = PriorityQueue()\n",
    "    Q.put((0, start))\n",
    "    \n",
    "    while not Q.empty():\n",
    "        u = Q.get()[1]\n",
    "        \n",
    "        connection_u = point_dict[u]['connection_lst']\n",
    "        u_latitude = point_dict[u]['latitude']\n",
    "        u_longitude = point_dict[u]['longitude']\n",
    "        u_coor = (u_latitude, u_longitude)\n",
    "\n",
    "        for v in connection_u:\n",
    "            v_latitude = point_dict[v]['latitude']\n",
    "            v_longitude = point_dict[v]['longitude']\n",
    "            v_coor = (v_latitude, v_longitude)\n",
    "            \n",
    "            distance_u_v = get_distance(u_coor, v_coor)\n",
    "            if dist[u] + distance_u_v < dist[v]:\n",
    "                dist[v] = dist[u] + distance_u_v\n",
    "                pred[v] = u\n",
    "                Q.put((dist[u] + distance_u_v, v))\n",
    "    \n",
    "    output_lst = []\n",
    "    current = end\n",
    "    while current != start:\n",
    "        output_lst.append(current)\n",
    "        current = pred[current]\n",
    "    output_lst.append(start)\n",
    "    output_lst = list(reversed(output_lst))\n",
    "    \n",
    "    # Output list is a list of all points on the route\n",
    "    return dist, pred, output_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. PM2.5 router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "def getHTMLtext(url):       \n",
    "    request = requests.get(url, timeout = 30)   \n",
    "    request.raise_for_status()        \n",
    "    request.encoding = request.apparent_encoding            \n",
    "    return request.text \n",
    "\n",
    "def get_weather_data():\n",
    "    with open('wind_direction.pkl', 'rb') as tf:\n",
    "        wind_direction_dict = pickle.load(tf)\n",
    "        \n",
    "    with open('condition.pkl', 'rb') as tf:\n",
    "        condition_dict = pickle.load(tf)\n",
    "    date = time.strftime(\"%Y-%m-%d %H\", time.localtime())\n",
    "    time_struct = time.strptime(date, \"%Y-%m-%d %H\")\n",
    "    timestamp= int(time.mktime(time_struct))\n",
    "    year = time.strftime(\"%Y\", time.localtime())\n",
    "    month = time.strftime(\"%m\", time.localtime())\n",
    "    day = time.strftime(\"%d\", time.localtime())\n",
    "    \n",
    "    text = getHTMLtext('https://api.weather.com/v1/location/YMML:9:AU/observations/historical.json?apiKey=e1f10a1e78da46f5b10a1e78da96f525&units=e&startDate='+ year + month + day + '&endDate='+ year + month + day)\n",
    "    text_json = json.loads(text)\n",
    "    weather_dict = {}\n",
    "    temperture_lst = []\n",
    "    condition_lst = []\n",
    "    humidity_lst = []\n",
    "    pressure_lst = []\n",
    "    wind_speed_lst = []\n",
    "    wind_direction_lst = []\n",
    "    data_lst = text_json['observations']\n",
    "    for weather in data_lst:\n",
    "        # find the current time\n",
    "        if weather['valid_time_gmt'] == timestamp:\n",
    "            weather_dict['temperture'] = weather['temp']\n",
    "            weather_dict['condition'] = condition_dict[weather['wx_phrase']]\n",
    "            weather_dict['humidity'] = weather['rh']/100\n",
    "            weather_dict['pressure'] = weather['pressure']\n",
    "            weather_dict['wind_speed'] = weather['wspd']\n",
    "            weather_dict['wind_direction'] = wind_direction_dict[weather['wdir_cardinal']]\n",
    "    return weather_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "import geopy.distance\n",
    "import pickle\n",
    "\n",
    "def get_distance(coords_1, coords_2):\n",
    "    return geopy.distance.geodesic(coords_1, coords_2).m\n",
    "\n",
    "def get_street_PM():\n",
    "    # load model\n",
    "    load_model = pickle.load(open('new_xgboost.dat', 'rb'))\n",
    "    traffic = traffic_volume()\n",
    "    EPA_PM = get_EPA_PM(site_id_dict['Melbourne CBD'])[0]\n",
    "    if EPA_PM <= 0:\n",
    "        EPA_PM = regression_kriging(site_id_dict)\n",
    "\n",
    "    weather_dict = get_weather_data()\n",
    "    \n",
    "    predict_data = pd.DataFrame({      \n",
    "                                    'traffic': traffic,\n",
    "                                    'temperture': [weather_dict['temperture'] for i in traffic],\n",
    "                                    'relative_humidity': [weather_dict['humidity'] for i in traffic],\n",
    "                                    'wind_direction': [weather_dict['wind_direction'] for i in traffic],\n",
    "                                    'wind_speed': [weather_dict['wind_speed'] for i in traffic],\n",
    "                                    'pressure': [weather_dict['pressure'] for i in traffic],\n",
    "                                    'condition': [weather_dict['condition'] for i in traffic],\n",
    "                                    'EPA': [EPA_PM for i in traffic],\n",
    "                                              })\n",
    "\n",
    "\n",
    "    # Get the street level PM2.5\n",
    "    PM_lst = list(load_model.predict(predict_data))\n",
    "    street_level_PM = dict()\n",
    "    count = 0\n",
    "    for i in connection_set:\n",
    "        street_level_PM[i] = PM_lst[count]\n",
    "        count += 1\n",
    "\n",
    "\n",
    "    return street_level_PM\n",
    "\n",
    "def calculate_conn_info(walking_speed=83, respiration_rates=9, street_level_PM=street_level_PM):\n",
    "    conn_info = dict()\n",
    "    distance_min = float(\"inf\")\n",
    "    distance_max = 0\n",
    "    exposure_min = float(\"inf\")\n",
    "    exposure_max = 0\n",
    "    for u in point_dict.keys():\n",
    "        connection_u = point_dict[u]['connection_lst']\n",
    "        u_coor = (point_dict[u]['latitude'], point_dict[u]['longitude'])\n",
    "\n",
    "        for v in connection_u:\n",
    "            conn_info[(u,v)] = dict()\n",
    "            v_coor = ( point_dict[v]['latitude'], point_dict[v]['longitude'])\n",
    "            \n",
    "            distance_u_v = get_distance(u_coor, v_coor)\n",
    "            \n",
    "            if (u,v) in connection_set:\n",
    "                node_PM = street_level_PM[(u,v)]\n",
    "            else:\n",
    "                node_PM = street_level_PM[(v, u)]\n",
    "                \n",
    "            exposure = (distance_u_v / walking_speed) * respiration_rates * (node_PM / 1000)\n",
    "            \n",
    "            conn_info[(u,v)]['distance'] = distance_u_v\n",
    "            conn_info[(u,v)]['exposure'] = exposure\n",
    "            \n",
    "            if distance_u_v < distance_min:\n",
    "                distance_min = distance_u_v\n",
    "            if distance_u_v > distance_max:\n",
    "                distance_max = distance_u_v\n",
    "            \n",
    "            if exposure < exposure_min:\n",
    "                exposure_min = exposure\n",
    "            if exposure > exposure_max:\n",
    "                exposure_max = exposure\n",
    "                \n",
    "    conn_info['distance_min'] = distance_min\n",
    "    conn_info['distance_max'] = distance_max\n",
    "    conn_info['exposure_min'] = exposure_min\n",
    "    conn_info['exposure_max'] = exposure_max\n",
    "    return conn_info\n",
    "        \n",
    "def dijkstra_PM(start, end, point_dict, w, walking_speed=83, respiration_rates=9):\n",
    "    \n",
    "    # street_level_PM = get_street_PM()\n",
    "    dist = dict()\n",
    "    for i in point_dict.keys():\n",
    "        dist[i] = float(\"inf\")\n",
    "    \n",
    "    pred = dict()\n",
    "    for i in point_dict.keys():\n",
    "        pred[i] = 0\n",
    "\n",
    "    dist[start] = 0\n",
    "    \n",
    "    Q = PriorityQueue()\n",
    "    Q.put((0, start))\n",
    "    \n",
    "    conn_info = calculate_conn_info(walking_speed, respiration_rates, street_level_PM)\n",
    "    \n",
    "    while not Q.empty():\n",
    "        u = Q.get()[1]\n",
    "        \n",
    "        connection_u = point_dict[u]['connection_lst']\n",
    "        u_coor = (point_dict[u]['latitude'], point_dict[u]['longitude'])\n",
    "\n",
    "        for v in connection_u:\n",
    "            exposure = conn_info[(u,v)]['exposure']\n",
    "            distance_u_v = conn_info[(u,v)]['distance']\n",
    "            distance_min = conn_info['distance_min']\n",
    "            distance_max = conn_info['distance_max']\n",
    "            exposure_min = conn_info['exposure_min']\n",
    "            exposure_max = conn_info['exposure_max']\n",
    "#             min_max_distance = (distance_u_v - distance_min) / (distance_max - distance_min)\n",
    "#             min_max_exposure = (exposure - exposure_min) / (exposure_max - exposure_min)\n",
    "        \n",
    "#             weight = w * min_max_distance + (1-w) * min_max_exposure\n",
    "\n",
    "            weight = w * (distance_u_v/distance_max) + (1-w)*(exposure / exposure_max)\n",
    "            if dist[u] + weight < dist[v]:\n",
    "                dist[v] = dist[u] + weight\n",
    "                pred[v] = u\n",
    "                Q.put((dist[u] + weight, v))\n",
    "    \n",
    "    \n",
    "    output_lst = []\n",
    "    current = end\n",
    "    \n",
    "    while current != start:\n",
    "        output_lst.append(current)\n",
    "        current = pred[current]\n",
    "    output_lst.append(start)\n",
    "    output_lst = list(reversed(output_lst))\n",
    "    return dist, pred, output_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to compare the distance and PM2.5 value of each route\n",
    "def Calculate_distance(route):\n",
    "    distance = 0\n",
    "    for i in range(1, len(route)):\n",
    "        point_i = route[i]\n",
    "        point_j = route[i - 1]\n",
    "        i_coor = (point_dict[point_i]['latitude'], point_dict[point_i]['longitude'])\n",
    "        j_coor = (point_dict[point_j]['latitude'], point_dict[point_j]['longitude'])\n",
    "        \n",
    "        distance += get_distance(i_coor, j_coor)\n",
    "        \n",
    "    return distance\n",
    "\n",
    "def Calculate_PM(route, walking_speed, respiration_rates):\n",
    "    PM = 0\n",
    "    for i in range(1, len(route)):\n",
    "        point_i = route[i]\n",
    "        point_j = route[i - 1]\n",
    "        i_coor = (point_dict[point_i]['latitude'], point_dict[point_i]['longitude'])\n",
    "        j_coor = (point_dict[point_j]['latitude'], point_dict[point_j]['longitude'])\n",
    "        \n",
    "        distance = get_distance(i_coor, j_coor)\n",
    "        \n",
    "        if (point_i,point_j) in connection_set:\n",
    "            node_PM = street_level_PM[(point_i,point_j)]\n",
    "        else:\n",
    "            node_PM = street_level_PM[(point_j,point_i)]\n",
    "                \n",
    "        PM += distance / walking_speed * respiration_rates * (node_PM / 1000)\n",
    "        \n",
    "    return PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_minimum_PM(start, end, walking_speed, respiration_rate):\n",
    "    route_lst = []\n",
    "    shortest_distance = dijkstra_distance(start, end, point_dict)[2]\n",
    "    minimum_PM = dijkstra_PM(start, end,point_dict,0,walking_speed, respiration_rate)[2]\n",
    "    route_lst.append(shortest_distance)\n",
    "    route_lst.append(minimum_PM)\n",
    "        \n",
    "    print(\"Distance of shortest distance: \", Calculate_distance(shortest_distance))\n",
    "    print(\"Distance of minimum PM: \", Calculate_distance(minimum_PM))\n",
    "    print()\n",
    "    \n",
    "    print(\"PM2.5 of shortest distance: \", Calculate_PM(shortest_distance, walking_speed, respiration_rate))\n",
    "    print(\"PM2.5 of minimum PM2.5: \", Calculate_PM(minimum_PM, walking_speed, respiration_rate))\n",
    "    print()\n",
    "    \n",
    "    return route_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(start, end, walking_speed, respiration_rate):\n",
    "    route_list = []\n",
    "    shortest_distance = dijkstra_distance(start, end, point_dict)[2]\n",
    "    minimum_PM = dijkstra_PM(start, end,point_dict,0,walking_speed, respiration_rate)[2]\n",
    "    \n",
    "    print(\"Distance of shortest distance: \", Calculate_distance(shortest_distance))\n",
    "    print(\"Distance of minimum PM: \", Calculate_distance(minimum_PM))\n",
    "    print()\n",
    "    \n",
    "    print(\"PM2.5 of shortest distance: \", Calculate_PM(shortest_distance, walking_speed, respiration_rate))\n",
    "    print(\"PM2.5 of minimum PM2.5: \", Calculate_PM(minimum_PM, walking_speed, respiration_rate))\n",
    "    print()\n",
    "    \n",
    "    w = 0\n",
    "    while w < 1:\n",
    "        print(\"w =\",w)\n",
    "        alternate_route = dijkstra_PM(start, end,point_dict, 1-w, walking_speed, respiration_rate)[2]\n",
    "        if alternate_route not in route_list:\n",
    "            route_list.append(alternate_route)\n",
    "        print('alternative distance', Calculate_distance(alternate_route))\n",
    "        print('alternative PM', Calculate_PM(alternate_route,walking_speed, respiration_rate))\n",
    "        print()\n",
    "        w += 0.1\n",
    "        w = round(w,1)\n",
    "    \n",
    "    print(\"number of route\", len(route_list))\n",
    "    return route_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_route(filename, route_lst):\n",
    "    name_str = \"line\"\n",
    "    name_lst = []\n",
    "    \n",
    "    wkt_lst = []\n",
    "    for i in range(len(route_lst)):\n",
    "        name = name_str + str(i+1)\n",
    "        name_lst.append(name)\n",
    "        wkt_lst.append(draw_router(route_lst[i]))\n",
    "        \n",
    "    line_df = pd.DataFrame({\n",
    "            'WKT': wkt_lst,\n",
    "            'Name': name_lst\n",
    "                                          })\n",
    "    line_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance of shortest distance:  1599.1190158343097\n",
      "Distance of minimum PM:  1623.8300439351501\n",
      "\n",
      "PM2.5 of shortest distance:  0.9297262602929167\n",
      "PM2.5 of minimum PM2.5:  0.8791528345433446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minimum_1 = test_minimum_PM(\"7\", \"177\", 83, 9.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance of shortest distance:  1373.9385653689583\n",
      "Distance of minimum PM:  1389.1070285984629\n",
      "\n",
      "PM2.5 of shortest distance:  0.8243264832191097\n",
      "PM2.5 of minimum PM2.5:  0.7752941421105705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minimum_1 = test_minimum_PM(\"46\", \"193\", 83, 9.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance of shortest distance:  1592.3602699144558\n",
      "Distance of minimum PM:  1607.0750840083504\n",
      "\n",
      "PM2.5 of shortest distance:  0.9897512562027646\n",
      "PM2.5 of minimum PM2.5:  0.9156614162445601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minimum_1 = test_minimum_PM(\"45\", \"160\", 83, 9.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance of shortest distance:  1595.166095889275\n",
      "Distance of minimum PM:  1612.3827401883898\n",
      "\n",
      "PM2.5 of shortest distance:  0.9517788386390515\n",
      "PM2.5 of minimum PM2.5:  0.8796965440859574\n",
      "\n",
      "w = 0\n",
      "alternative distance 1595.166095889275\n",
      "alternative PM 0.9517788386390515\n",
      "\n",
      "w = 0.1\n",
      "alternative distance 1595.370587820574\n",
      "alternative PM 0.9145035207993264\n",
      "\n",
      "w = 0.2\n",
      "alternative distance 1603.7560318270032\n",
      "alternative PM 0.8904084373025671\n",
      "\n",
      "w = 0.3\n",
      "alternative distance 1603.7560318270032\n",
      "alternative PM 0.8904084373025671\n",
      "\n",
      "w = 0.4\n",
      "alternative distance 1612.3827401883898\n",
      "alternative PM 0.8796965440859574\n",
      "\n",
      "w = 0.5\n",
      "alternative distance 1612.3827401883898\n",
      "alternative PM 0.8796965440859574\n",
      "\n",
      "w = 0.6\n",
      "alternative distance 1612.3827401883898\n",
      "alternative PM 0.8796965440859574\n",
      "\n",
      "w = 0.7\n",
      "alternative distance 1612.3827401883898\n",
      "alternative PM 0.8796965440859574\n",
      "\n",
      "w = 0.8\n",
      "alternative distance 1612.3827401883898\n",
      "alternative PM 0.8796965440859574\n",
      "\n",
      "w = 0.9\n",
      "alternative distance 1612.3827401883898\n",
      "alternative PM 0.8796965440859574\n",
      "\n",
      "number of route 4\n"
     ]
    }
   ],
   "source": [
    "route = test_function(\"99\", \"157\", 83, 9.1)\n",
    "\n",
    "# used to draw the line in google map\n",
    "# save_route(\"alternative_route.csv\", route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
